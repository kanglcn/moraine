{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e365ed6-e4e5-44fb-9bc5-da2beb29670c",
   "metadata": {},
   "source": [
    "# chunk\n",
    "\n",
    "> internal utilities for chunkwise data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f94bd-09ce-4ba1-bcfc-38c72a7f706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chunk_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396af32a-8c43-4df8-8d83-ed51bb478fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42026ed4-ec41-4832-bf53-7579d1762872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import itertools\n",
    "from moraine.rtree import HilbertRtree\n",
    "from scipy.spatial import KDTree\n",
    "from joblib import Parallel, delayed\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc93fd2-9efb-4c13-936f-52867b44a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fill_slice(\n",
    "    shape, # numpy arr, cupy arr, zarr,\n",
    "    slices, # tuple of slice object, len == data_arr.ndim\n",
    "):\n",
    "    out_slices = []\n",
    "    for i in range(len(slices)):\n",
    "        slice_i = slices[i]\n",
    "        if slice_i.start is None:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = slice_i.start\n",
    "        assert start>=0\n",
    "        assert start<shape[i]\n",
    "        if slice_i.stop is None:\n",
    "            stop = shape[i]\n",
    "        else:\n",
    "            stop = slice_i.stop\n",
    "        assert stop > start\n",
    "        assert stop <= shape[i]\n",
    "        assert (slice_i.step is None) or (slice_i.step == 1)\n",
    "        step = 1\n",
    "        out_slices.append(slice(start,stop,step))\n",
    "    return tuple(out_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b69a49-19fa-4071-9327-f0ea5c980555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def all_chunk_slices(\n",
    "    shape, # np.array, cp.array,zarr\n",
    "    chunks,\n",
    "):\n",
    "    '''get the slices for every input chunks'''\n",
    "    out_slices = []\n",
    "    for shape_, chunk_ in zip(shape,chunks):\n",
    "        if chunk_ <0: chunk_ = shape_\n",
    "        bound_1dim = np.arange(0,shape_+chunk_,chunk_)\n",
    "        if bound_1dim[-1] > shape_: bound_1dim[-1] = shape_\n",
    "\n",
    "        slice_1dim = []\n",
    "        for j in range(bound_1dim.shape[0]-1):\n",
    "            slice_1dim.append(slice(int(bound_1dim[j]),int(bound_1dim[j+1])))\n",
    "        out_slices.append(slice_1dim)\n",
    "    out_slices = list(itertools.product(*out_slices))\n",
    "    return out_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96fa860-c6e0-4820-92d5-81c953874c90",
   "metadata": {},
   "source": [
    "usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea8767-31b8-4638-a1e3-e192a1cdaa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(slice(0, 15, None), slice(0, 40, None), slice(0, 6, None)),\n",
       " (slice(0, 15, None), slice(0, 40, None), slice(6, 11, None)),\n",
       " (slice(0, 15, None), slice(40, 80, None), slice(0, 6, None)),\n",
       " (slice(0, 15, None), slice(40, 80, None), slice(6, 11, None)),\n",
       " (slice(0, 15, None), slice(80, 100, None), slice(0, 6, None)),\n",
       " (slice(0, 15, None), slice(80, 100, None), slice(6, 11, None)),\n",
       " (slice(15, 30, None), slice(0, 40, None), slice(0, 6, None)),\n",
       " (slice(15, 30, None), slice(0, 40, None), slice(6, 11, None)),\n",
       " (slice(15, 30, None), slice(40, 80, None), slice(0, 6, None)),\n",
       " (slice(15, 30, None), slice(40, 80, None), slice(6, 11, None)),\n",
       " (slice(15, 30, None), slice(80, 100, None), slice(0, 6, None)),\n",
       " (slice(15, 30, None), slice(80, 100, None), slice(6, 11, None)),\n",
       " (slice(30, 45, None), slice(0, 40, None), slice(0, 6, None)),\n",
       " (slice(30, 45, None), slice(0, 40, None), slice(6, 11, None)),\n",
       " (slice(30, 45, None), slice(40, 80, None), slice(0, 6, None)),\n",
       " (slice(30, 45, None), slice(40, 80, None), slice(6, 11, None)),\n",
       " (slice(30, 45, None), slice(80, 100, None), slice(0, 6, None)),\n",
       " (slice(30, 45, None), slice(80, 100, None), slice(6, 11, None)),\n",
       " (slice(45, 50, None), slice(0, 40, None), slice(0, 6, None)),\n",
       " (slice(45, 50, None), slice(0, 40, None), slice(6, 11, None)),\n",
       " (slice(45, 50, None), slice(40, 80, None), slice(0, 6, None)),\n",
       " (slice(45, 50, None), slice(40, 80, None), slice(6, 11, None)),\n",
       " (slice(45, 50, None), slice(80, 100, None), slice(0, 6, None)),\n",
       " (slice(45, 50, None), slice(80, 100, None), slice(6, 11, None))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((50,100,11))\n",
    "chunks = (15,40,6)\n",
    "all_chunk_slices(a.shape,chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bea2e6-0d98-4956-8580-96d65ce81dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(slice(0, 15, None),),\n",
       " (slice(15, 30, None),),\n",
       " (slice(30, 45, None),),\n",
       " (slice(45, 60, None),),\n",
       " (slice(60, 75, None),),\n",
       " (slice(75, 90, None),),\n",
       " (slice(90, 105, None),),\n",
       " (slice(105, 120, None),),\n",
       " (slice(120, 135, None),),\n",
       " (slice(135, 150, None),),\n",
       " (slice(150, 165, None),),\n",
       " (slice(165, 180, None),),\n",
       " (slice(180, 195, None),),\n",
       " (slice(195, 210, None),),\n",
       " (slice(210, 225, None),),\n",
       " (slice(225, 240, None),),\n",
       " (slice(240, 255, None),),\n",
       " (slice(255, 270, None),),\n",
       " (slice(270, 285, None),),\n",
       " (slice(285, 300, None),),\n",
       " (slice(300, 315, None),),\n",
       " (slice(315, 330, None),),\n",
       " (slice(330, 343, None),)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(343)\n",
    "all_chunk_slices(a.shape,(15,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ed893-d100-4c55-b11f-bca5b9762261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def all_chunk_slices_with_overlap(\n",
    "    shape, \n",
    "    chunks, \n",
    "    depths,\n",
    "):\n",
    "    '''get the slices for every input chunks with overlap'''\n",
    "    out_slices = []\n",
    "    for shape_, chunk_, depth_ in zip(shape,chunks,depths):\n",
    "        if chunk_ <0: chunk_ = shape_\n",
    "        starts_1dim = np.arange(-depth_,shape_-depth_,chunk_)\n",
    "        starts_1dim[starts_1dim<0] = 0\n",
    "        ends_1dim = np.arange(chunk_+depth_,shape_+chunk_+depth_,chunk_)\n",
    "        ends_1dim[ends_1dim>shape_] = shape_\n",
    "\n",
    "        slice_1dim = []\n",
    "        for j in range(starts_1dim.shape[0]):\n",
    "            slice_1dim.append(slice(int(starts_1dim[j]),int(ends_1dim[j])))\n",
    "        out_slices.append(slice_1dim)\n",
    "    out_slices = list(itertools.product(*out_slices))\n",
    "    return out_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574622d-7d48-487a-9cc5-f8d2adc5ea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(slice(0, 16, None), slice(0, 42, None), slice(0, 6, None)),\n",
       " (slice(0, 16, None), slice(0, 42, None), slice(6, 11, None)),\n",
       " (slice(0, 16, None), slice(38, 82, None), slice(0, 6, None)),\n",
       " (slice(0, 16, None), slice(38, 82, None), slice(6, 11, None)),\n",
       " (slice(0, 16, None), slice(78, 100, None), slice(0, 6, None)),\n",
       " (slice(0, 16, None), slice(78, 100, None), slice(6, 11, None)),\n",
       " (slice(14, 31, None), slice(0, 42, None), slice(0, 6, None)),\n",
       " (slice(14, 31, None), slice(0, 42, None), slice(6, 11, None)),\n",
       " (slice(14, 31, None), slice(38, 82, None), slice(0, 6, None)),\n",
       " (slice(14, 31, None), slice(38, 82, None), slice(6, 11, None)),\n",
       " (slice(14, 31, None), slice(78, 100, None), slice(0, 6, None)),\n",
       " (slice(14, 31, None), slice(78, 100, None), slice(6, 11, None)),\n",
       " (slice(29, 46, None), slice(0, 42, None), slice(0, 6, None)),\n",
       " (slice(29, 46, None), slice(0, 42, None), slice(6, 11, None)),\n",
       " (slice(29, 46, None), slice(38, 82, None), slice(0, 6, None)),\n",
       " (slice(29, 46, None), slice(38, 82, None), slice(6, 11, None)),\n",
       " (slice(29, 46, None), slice(78, 100, None), slice(0, 6, None)),\n",
       " (slice(29, 46, None), slice(78, 100, None), slice(6, 11, None)),\n",
       " (slice(44, 50, None), slice(0, 42, None), slice(0, 6, None)),\n",
       " (slice(44, 50, None), slice(0, 42, None), slice(6, 11, None)),\n",
       " (slice(44, 50, None), slice(38, 82, None), slice(0, 6, None)),\n",
       " (slice(44, 50, None), slice(38, 82, None), slice(6, 11, None)),\n",
       " (slice(44, 50, None), slice(78, 100, None), slice(0, 6, None)),\n",
       " (slice(44, 50, None), slice(78, 100, None), slice(6, 11, None))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((50,100,11))\n",
    "chunks = (15,40,6)\n",
    "depth = (1,2,0)\n",
    "all_chunk_slices_with_overlap(a.shape,chunks,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4afa15f-e896-437f-91c4-2c54a0af2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def chunkwise_slicing_mapping(\n",
    "    shape,\n",
    "    chunks,\n",
    "    depths,\n",
    "):\n",
    "    '''get the slices for every input chunks with overlap\n",
    "    output chunks without overlap and their mapping slices'''\n",
    "    in_slices = []; out_slices = []; map_slices = []\n",
    "    for shape_, chunk_, depth_ in zip(shape,chunks,depths):\n",
    "        if chunk_ <0: chunk_ = shape_\n",
    "        in_starts_1dim = np.arange(-depth_,shape_-depth_,chunk_)\n",
    "        in_starts_1dim[in_starts_1dim<0] = 0\n",
    "        in_ends_1dim = np.arange(chunk_+depth_,shape_+chunk_+depth_,chunk_)\n",
    "        in_ends_1dim[in_ends_1dim>shape_] = shape_\n",
    "        out_starts_1dim = np.arange(0,shape_,chunk_)\n",
    "        out_ends_1dim = np.arange(chunk_,shape_+chunk_,chunk_)\n",
    "        out_ends_1dim[out_ends_1dim>shape_] = shape_\n",
    "\n",
    "        assert len(in_starts_1dim) == len(out_starts_1dim)\n",
    "        assert len(in_ends_1dim) == len(out_ends_1dim)\n",
    "\n",
    "        in_slice_1dim = []; out_slice_1dim = []; map_slice_1dim = []\n",
    "        for in_start, in_end, out_start, out_end in zip(in_starts_1dim, in_ends_1dim, out_starts_1dim, out_ends_1dim):\n",
    "            in_slice_1dim.append(slice(int(in_start),int(in_end)))\n",
    "            out_slice_1dim.append(slice(int(out_start),int(out_end)))\n",
    "            offset = out_start-in_start\n",
    "            map_slice_1dim.append(slice(int(offset),int(offset+out_end-out_start)))\n",
    "\n",
    "        in_slices.append(in_slice_1dim)\n",
    "        out_slices.append(out_slice_1dim)\n",
    "        map_slices.append(map_slice_1dim)\n",
    "\n",
    "    in_slices = list(itertools.product(*in_slices))\n",
    "    out_slices = list(itertools.product(*out_slices))\n",
    "    map_slices = list(itertools.product(*map_slices))\n",
    "    return in_slices, out_slices, map_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10308451-b550-48ab-90d3-575cc040466b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(slice(0, 16, None), slice(0, 42, None)),\n",
       "  (slice(0, 16, None), slice(38, 82, None)),\n",
       "  (slice(0, 16, None), slice(78, 100, None)),\n",
       "  (slice(14, 31, None), slice(0, 42, None)),\n",
       "  (slice(14, 31, None), slice(38, 82, None)),\n",
       "  (slice(14, 31, None), slice(78, 100, None)),\n",
       "  (slice(29, 46, None), slice(0, 42, None)),\n",
       "  (slice(29, 46, None), slice(38, 82, None)),\n",
       "  (slice(29, 46, None), slice(78, 100, None)),\n",
       "  (slice(44, 50, None), slice(0, 42, None)),\n",
       "  (slice(44, 50, None), slice(38, 82, None)),\n",
       "  (slice(44, 50, None), slice(78, 100, None))],\n",
       " [(slice(0, 15, None), slice(0, 40, None)),\n",
       "  (slice(0, 15, None), slice(40, 80, None)),\n",
       "  (slice(0, 15, None), slice(80, 100, None)),\n",
       "  (slice(15, 30, None), slice(0, 40, None)),\n",
       "  (slice(15, 30, None), slice(40, 80, None)),\n",
       "  (slice(15, 30, None), slice(80, 100, None)),\n",
       "  (slice(30, 45, None), slice(0, 40, None)),\n",
       "  (slice(30, 45, None), slice(40, 80, None)),\n",
       "  (slice(30, 45, None), slice(80, 100, None)),\n",
       "  (slice(45, 50, None), slice(0, 40, None)),\n",
       "  (slice(45, 50, None), slice(40, 80, None)),\n",
       "  (slice(45, 50, None), slice(80, 100, None))],\n",
       " [(slice(0, 15, None), slice(0, 40, None)),\n",
       "  (slice(0, 15, None), slice(2, 42, None)),\n",
       "  (slice(0, 15, None), slice(2, 22, None)),\n",
       "  (slice(1, 16, None), slice(0, 40, None)),\n",
       "  (slice(1, 16, None), slice(2, 42, None)),\n",
       "  (slice(1, 16, None), slice(2, 22, None)),\n",
       "  (slice(1, 16, None), slice(0, 40, None)),\n",
       "  (slice(1, 16, None), slice(2, 42, None)),\n",
       "  (slice(1, 16, None), slice(2, 22, None)),\n",
       "  (slice(1, 6, None), slice(0, 40, None)),\n",
       "  (slice(1, 6, None), slice(2, 42, None)),\n",
       "  (slice(1, 6, None), slice(2, 22, None))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((50,100))\n",
    "chunks = (15,40)\n",
    "depth = [1,2] # or {0:1, 1:2, 2:3}\n",
    "chunkwise_slicing_mapping(a.shape,chunks,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833bb96-4f17-4241-bc01-0ee2a65462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@njit(fastmath=True, cache=True, nogil=True)\n",
    "def normalize_xy_stack(x_chunk, y_chunk):\n",
    "    \"\"\"\n",
    "    Normalize x, y to [0, 1] range and stack into shape (N, 2).\n",
    "    Returns normalized positions and (x_min, x_max, y_min, y_max)\n",
    "    \"\"\"\n",
    "    x_min = x_chunk.min()\n",
    "    x_max = x_chunk.max()\n",
    "    y_min = y_chunk.min()\n",
    "    y_max = y_chunk.max()\n",
    "\n",
    "    # Avoid division by zero\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    if x_range == 0.0:\n",
    "        x_range = 1.0\n",
    "    if y_range == 0.0:\n",
    "        y_range = 1.0\n",
    "\n",
    "    n = x_chunk.size\n",
    "    pos_norm = np.empty((n, 2), dtype=x_chunk.dtype)\n",
    "    for i in range(n):\n",
    "        pos_norm[i, 0] = (x_chunk[i] - x_min) / x_range\n",
    "        pos_norm[i, 1] = (y_chunk[i] - y_min) / y_range\n",
    "\n",
    "    return pos_norm, x_min, x_max, y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6991d16-4aba-4d8a-9c05-30f00eb9cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@njit(fastmath=True, cache=True, nogil=True)\n",
    "def get_boundary_idx(x_norm, y_norm, k=128, bound_ratio_init=0.05, bound_ratio_step=0.05):\n",
    "    \"\"\"\n",
    "    Select boundary point indices from normalized coordinates.\n",
    "\n",
    "    Args:\n",
    "        x_norm, y_norm: normalized 1D arrays (0â€“1 range)\n",
    "        k: least number of boundary points\n",
    "        bound_ratio_init: initial boundary width ratio\n",
    "        bound_ratio_step: increment step if not enough points\n",
    "\n",
    "    Returns:\n",
    "        bound_idx: 1D array of indices of boundary points\n",
    "    \"\"\"\n",
    "    n_chunk = x_norm.size\n",
    "    if n_chunk < 2 * k:\n",
    "        return np.arange(n_chunk)\n",
    "\n",
    "    br = bound_ratio_init\n",
    "    bound_idx = np.empty(n_chunk, dtype=np.int64)\n",
    "    while True:\n",
    "        count = 0\n",
    "        for i in range(n_chunk):\n",
    "            x = x_norm[i]\n",
    "            y = y_norm[i]\n",
    "            if (x < br) or (x > 1.0 - br) or (y < br) or (y > 1.0 - br):\n",
    "                bound_idx[count] = i\n",
    "                count += 1\n",
    "\n",
    "        if count >= k or br >= 0.5:\n",
    "            return bound_idx[:count]\n",
    "\n",
    "        br += bound_ratio_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c8b5a-3af2-4b4e-b87b-e94364905dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@njit(fastmath=True, cache=True, nogil=True)\n",
    "def normalize_and_get_boundary(x_chunk, y_chunk, k=128, bound_ratio_init=0.05, bound_ratio_step=0.05):\n",
    "    \"\"\"\n",
    "    Combined normalization and boundary index selection.\n",
    "    \"\"\"\n",
    "    pos_norm, x_min, x_max, y_min, y_max = normalize_xy_stack(x_chunk, y_chunk)\n",
    "    bound_idx = get_boundary_idx(pos_norm[:, 0], pos_norm[:, 1], k, bound_ratio_init, bound_ratio_step)\n",
    "    return pos_norm, x_min, x_max, y_min, y_max, bound_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624d38c-a0e0-4a61-88c6-e467b6d5e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_chunk(i, bound, x, y, k, chunks, rtree_bounds_tree, bound_ratio_init, bound_ratio_step):\n",
    "    start = int(bound[i])\n",
    "    end = int(bound[i + 1])\n",
    "    x_chunk = x[start:end]\n",
    "    y_chunk = y[start:end]\n",
    "    n_chunk = end - start\n",
    "\n",
    "    # === Step 1. Normalize + boundary detection (Numba) ===\n",
    "    pos_norm, x_min, x_max, y_min, y_max, bound_idx = normalize_and_get_boundary(\n",
    "        x_chunk, y_chunk, k, bound_ratio_init, bound_ratio_step\n",
    "    )\n",
    "    x_norm, y_norm = pos_norm[:, 0], pos_norm[:, 1]\n",
    "\n",
    "    # === Step 2. Estimate distance of k-th NN for boundary points ===\n",
    "    tree = KDTree(pos_norm)\n",
    "    dd = tree.query(pos_norm[bound_idx], k=[k], workers=1)[0]\n",
    "    max_dd = np.max(dd)\n",
    "\n",
    "    # === Step 3. Compute halo region and query ===\n",
    "    y_halo_size = max_dd * (y_max - y_min)\n",
    "    x_halo_size = max_dd * (x_max - x_min)\n",
    "    halo_bounds = [x_min - x_halo_size, y_min - y_halo_size,\n",
    "                   x_max + x_halo_size, y_max + y_halo_size]\n",
    "    rtree = HilbertRtree(rtree_bounds_tree, x.shape[0], chunks)\n",
    "    halo_idx = rtree.bbox_query(halo_bounds, x, y)\n",
    "\n",
    "    # === Step 4. Build KDTree for halo points and find input indices ===\n",
    "    x_halo, y_halo = x[halo_idx], y[halo_idx]\n",
    "    tree = KDTree(np.stack((x_halo, y_halo), axis=-1))\n",
    "    in_idx = tree.query(np.stack((x_chunk, y_chunk), axis=-1), k=k, workers=1)[1]\n",
    "    in_idx = np.unique(in_idx)\n",
    "    in_idx = halo_idx[in_idx]  # map to global indices\n",
    "\n",
    "    # === Step 5. Compute mapping indices (local to chunk)\n",
    "    map_mask = (in_idx >= start) & (in_idx < end)\n",
    "    map_idx = np.flatnonzero(map_mask)\n",
    "\n",
    "    return in_idx, slice(start, end), map_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be32ac-ea5e-4d0f-8e0a-570c58682b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def chunkwise_knn_mapping(x, y, chunks, k=128, n_jobs=-1, bound_ratio_init=0.1, bound_ratio_step=0.1):\n",
    "    \"\"\"\n",
    "    Compute KNN mapping chunkwise with halo expansion.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    in_indices : list of np.ndarray\n",
    "        Indices of halo points per chunk.\n",
    "    out_slices : list of slice\n",
    "        Chunk output slices.\n",
    "    map_indices : list of np.ndarray\n",
    "        Mapping indices inside halo arrays.\n",
    "    \"\"\"\n",
    "    n = y.shape[0]\n",
    "    bound = np.arange(0, n + chunks, chunks)\n",
    "    if bound[-1] > n:\n",
    "        bound[-1] = n\n",
    "\n",
    "    # Build spatial index\n",
    "    rtree = HilbertRtree.build(x, y, page_size=chunks)\n",
    "    rtree_bounds_tree = rtree._bounds_tree\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs,backend='loky')(\n",
    "        delayed(process_chunk)(\n",
    "            i, bound, x, y, k, chunks, rtree_bounds_tree, bound_ratio_init, bound_ratio_step\n",
    "        )\n",
    "        for i in range(bound.shape[0] - 1)\n",
    "    )\n",
    "\n",
    "    in_indices, out_slices, map_indices = zip(*results)\n",
    "    return list(in_indices), list(out_slices), list(map_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9488e9d8-29a5-4b5e-a1cf-594fc56e143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb9fb7-933b-40b4-9c14-f722ba8b6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lon = zarr.open('../Tutorials/CLI/ps_processing/hix/ps_can_lon.zarr/',mode='r')[:]\n",
    "# lat = zarr.open('../Tutorials/CLI/ps_processing/hix/ps_can_lat.zarr/',mode='r')[:]\n",
    "\n",
    "lon = zarr.open('../../../William_Sound/192021/ps_processing/hix/ps_can_lon.zarr/',mode='r')[:]\n",
    "lat = zarr.open('../../../William_Sound/192021/ps_processing/hix/ps_can_lat.zarr/',mode='r')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d32f1-92dc-4ab9-9afd-07e2530a10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.68 s, sys: 796 ms, total: 4.47 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "in_indices, out_slices, map_indices = chunkwise_knn_mapping(lat, lon, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bac1d2-0d0f-4ea7-974a-6b5496d1cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def chunkwise_knn_mapping_(\n",
    "    x,\n",
    "    y,\n",
    "    chunks:int,\n",
    "    k = 128\n",
    "):\n",
    "    n = y.shape[0]\n",
    "    bound = np.arange(0,n+chunks,chunks)\n",
    "    if bound[-1] > n: bound[-1] = n\n",
    "    rtree = HilbertRtree.build(x,y,page_size=chunks)\n",
    "\n",
    "    out_slices = []\n",
    "    in_indices = []\n",
    "    map_indices = []\n",
    "    for i in range(bound.shape[0]-1):\n",
    "        start = int(bound[i])\n",
    "        end = int(bound[i+1])\n",
    "        out_slices.append(slice(start,end))\n",
    "\n",
    "        y_, x_ = y[start:end], x[start:end]\n",
    "        # normalize x and y here should be better and save the ratio!\n",
    "        y_max, y_min, x_max, x_min = y_.max(), y_.min(), x_.max(), x_.min()\n",
    "        y_norm = (y_ - y_min)/(y_max - y_min)\n",
    "        x_norm = (x_ - x_min)/(x_max - x_min)\n",
    "        pos_norm = np.stack((x_norm,y_norm),axis=-1)\n",
    "\n",
    "        # select boundary points\n",
    "        if chunks<2*k:\n",
    "            bound_idx = np.arange(chunks) # select all points as boundary points\n",
    "        else:\n",
    "            bound_ratio = 0.1\n",
    "            while True:\n",
    "                h_y, h_x = bound_ratio, bound_ratio\n",
    "                mask_boundary = (y_norm > 1-h_y) | (y_norm < h_y)|(x_norm > 1-h_x)|(x_norm < h_x)\n",
    "                bound_idx = np.nonzero(mask_boundary)[0]\n",
    "                bound_ratio = bound_ratio + 0.1\n",
    "                if len(bound_idx)>=k: break\n",
    "\n",
    "        # esimate distance of kth NN of the boundary points\n",
    "        tree = KDTree(pos_norm)\n",
    "        dd = tree.query(pos_norm[bound_idx],k=[k,],workers=-1)[0]\n",
    "        max_dd = np.max(dd)\n",
    "\n",
    "        # decide halo size and query halo points\n",
    "        y_halo_size, x_halo_size = max_dd*(y_max-y_min), max_dd*(x_max-x_min)\n",
    "        halo_bounds = [x_min-x_halo_size, y_min-y_halo_size, x_max+x_halo_size, y_max+y_halo_size]\n",
    "        halo_idx = rtree.bbox_query(halo_bounds, x, y)\n",
    "        #print(halo_idx.shape)\n",
    "        y_halo, x_halo = y[halo_idx], x[halo_idx]\n",
    "\n",
    "        # find input points: union of knn in halo points for points in the chunk \n",
    "        tree = KDTree(np.stack((x_halo, y_halo),axis=-1))\n",
    "        in_idx = tree.query(np.stack((x_, y_),axis=-1),k=k,workers=-1)[1]\n",
    "        in_idx = np.unique(in_idx)\n",
    "        in_idx = halo_idx[in_idx] # idx in all points\n",
    "        in_indices.append(in_idx)\n",
    "        # assert np.all(np.isin(np.arange(start,end),in_idx))\n",
    "\n",
    "        # indices that map points in the chunk from input points\n",
    "        map_idx = (in_idx>=start) & (in_idx<end)\n",
    "        map_idx = np.flatnonzero(map_idx)\n",
    "        map_indices.append(map_idx)\n",
    "\n",
    "    return in_indices, out_slices, map_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb54d8-faaf-46a8-8dbd-508e0eca969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# in_indices_, out_slices_, map_indices_ = chunkwise_knn_mapping_(lat, lon, 40000)\n",
    "# for i in range(len(in_indices)):\n",
    "#     np.testing.assert_array_equal(in_indices[i], in_indices_[i])\n",
    "#     np.testing.assert_array_equal(map_indices[i], map_indices_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4645ca1-d8d0-43ac-b34d-7d497345e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94325236-5120-47d2-a2c1-5210a1335ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
