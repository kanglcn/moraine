[
  {
    "objectID": "API/shp.html",
    "href": "API/shp.html",
    "title": "shp",
    "section": "",
    "text": "from scipy import stats\nimport numpy as np\nimport itertools"
  },
  {
    "objectID": "API/shp.html#kolmogorov-smirnov-ks-two-sample-test",
    "href": "API/shp.html#kolmogorov-smirnov-ks-two-sample-test",
    "title": "shp",
    "section": "Kolmogorov-Smirnov (KS) two-sample test",
    "text": "Kolmogorov-Smirnov (KS) two-sample test\n\nsource\n\nks_test\n\n ks_test (rmli:cupy.ndarray, az_half_win:int, r_half_win:int,\n          block_size:int=128)\n\nSHP identification based on Two-Sample Kolmogorov-Smirnov Test.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrmli\nndarray\n\nthe rmli stack, dtype: cupy.floating\n\n\naz_half_win\nint\n\nSHP identification half search window size in azimuth direction\n\n\nr_half_win\nint\n\nSHP identification half search window size in range direction\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe KS test statistics dist and p value p\n\n\n\nThe ks_test function apply the Two-Sample Kolmogorov-Smirnov Test on a stack of rmli images to identify SHPs candidate for further processing. This method is originally published in [@ferrettiNewAlgorithmProcessing2011]. This function is designed to run on GPU for high speed.\nThe rmli is a three dimentional cupy ndarray. The dtype should be float. From outerest to innerest, the three dimentions are azimuth, range and image. For each pixel P, a search window centered at P is defined by az_half_win and r_half_win. All pixels in this search window is compared with P by KS test. They are refered here as secondary pixels. The total number of secondary pixels (including P) is (2*az_half_win+1)*(2*r_half_win+1).\nThe returns are the ks test statistic which is the maximum value of the absolute difference between the emperical cumulative distribution functions of the two samples, and p value. Both of them are 4 dimentional cupy ndarrays. From outerest ot innerest, they are azimuth, range, secondary pixel relative azimuth, secondary pixel relative range. For P at the corner of the image where part of the search window is out of the image, the result is -1.\nHere is a simplest example. First simulate rmli time series of two pixels from two correlated normal distributions:\n\nsample_size = 20\nrng = np.random.default_rng()\nsample1 = stats.uniform.rvs(size=sample_size, random_state=rng).astype(cp.float32)\nsample2 = stats.norm.rvs(size=sample_size, random_state=rng).astype(cp.float32)\n\nConvert the data to cupy ndarray and make sure the dtype is cp.float32 and the data are sorted:\n\nrmli_stack = cp.stack((cp.asarray(sample1), cp.asarray(sample2))).reshape(1,2,sample_size)\nrmli_stack = rmli_stack.astype(cp.float32)\nrmli_stack.shape\n\n(1, 2, 20)\n\n\nThe shape of rmli_stack shows it contains 20 images. Each of the image has 1 pixel in azimuth dimention and 2 pixels in range dimention. Set the az_half_win and r_half_win to 1 and apply the ks_test function:\n\ndist,p = ks_test(rmli_stack,1,1)\nprint(dist.shape)\nprint(dist)\n\n(1, 2, 3, 3)\n[[[[-1.  -1.  -1. ]\n   [-1.   0.   0.5]\n   [-1.  -1.  -1. ]]\n\n  [[-1.  -1.  -1. ]\n   [ 0.5  0.  -1. ]\n   [-1.  -1.  -1. ]]]]\n\n\ndist is the ks test statistic. The shape of it shows for each pixel P in this 1*2 image, a 3*3 search window is defined and all pixels in this search window is test with P. The value 0 in dist is the ks test result of pixel P and pixel P itself. The value -1 means the secondary pixel is out of the image and no ks test is applied.\n\nprint(p.shape)\nprint(p)\n\n(1, 2, 3, 3)\n[[[[-1.         -1.         -1.        ]\n   [-1.          0.          0.00816168]\n   [-1.         -1.         -1.        ]]\n\n  [[-1.         -1.         -1.        ]\n   [ 0.00816168  0.         -1.        ]\n   [-1.         -1.         -1.        ]]]]\n\n\np is the ks test p value with same shape of dist.\n\nprint(stats.ks_2samp(sample1, sample2,method='asymp'))\n\nKstestResult(statistic=0.5, pvalue=0.00777741)\n\n\nBy comparing the result of ks_test and ks_2samp from scipy, the statistics are same which prove the correctness of ks_test. The difference in p value is because the approcimation method used are different but the orders of magnitudes are consistent."
  },
  {
    "objectID": "API/plot.html",
    "href": "API/plot.html",
    "title": "Plot",
    "section": "",
    "text": "source\n\nbg_alpha\n\n bg_alpha (pwr)"
  },
  {
    "objectID": "API/pl.html",
    "href": "API/pl.html",
    "title": "pl",
    "section": "",
    "text": "Code for generating data for test and doc\nimport cupy as cp\nimport numpy as np\nimport zarr\nimport h5py\nfrom decorrelation.shp import ks_test\nfrom decorrelation.co import emperical_co,emperical_co_sp, regularize_spectral\n\nfrom matplotlib import pyplot as plt"
  },
  {
    "objectID": "API/pl.html#emi",
    "href": "API/pl.html#emi",
    "title": "pl",
    "section": "EMI",
    "text": "EMI\n\nsource\n\nemi\n\n emi (coh:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncoh\nndarray\ncomplex coherence metrix,dtype cupy.complex\n\n\nReturns\ntuple\nestimated phase history ph, dtype complex; quality (minimum eigvalue, dtype float)\n\n\n\nemi is a phase estimator base on Eigendecomposition-based Maximum-likelihood-estimator of Interferometric phase (EMI) [@ansariEfficientPhaseEstimation2018] phase linking method.\nThe amplitude of coh should range between 0 and 1 and the phase of coh should be the interferometric phase. The returned phase is also complex but the amplitude is setted to 1. The quality factor is a measure for the inadequacy of EMI’s model that adding real-valued dyadic for calibration of real coherence matrix which is generally poorly estimated. It is supposed to larger than 1 and smaller means better.\nExample: Complex coherence matrix from a stack of 17 SLC images:\n\n\nCode for generating data for test and doc\nrslc = zarr.open('../../data/rslc.zarr/','r')\nrslc = cp.asarray(rslc[:])\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndel rmli\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\ndel p\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\n\n\n\nds_can_coh.shape\n\n(740397, 17, 17)\n\n\n\nds_can_ph, ds_can_emi_quality = emi(ds_can_coh)\nds_can_ph.shape, ds_can_emi_quality.shape\n\n((740397, 17), (740397,))\n\n\n\nds_can_emi_quality_2d = cp.empty_like(is_ds_can,dtype=ds_can_emi_quality.dtype)\nds_can_emi_quality_2d[:] = cp.nan\nds_can_emi_quality_2d[is_ds_can] = ds_can_emi_quality\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_emi_quality_2d),interpolation='nearest',vmin=1,vmax=1.3)\nax.set(title='DS EMI quality factor',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "API/pl.html#temporal-coherence-for-distributed-scatterer",
    "href": "API/pl.html#temporal-coherence-for-distributed-scatterer",
    "title": "pl",
    "section": "Temporal Coherence for Distributed Scatterer",
    "text": "Temporal Coherence for Distributed Scatterer\n\nsource\n\ntemp_coh\n\n temp_coh (coh:cupy.ndarray, ds_ph=<class 'cupy.ndarray'>)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncoh\nndarray\n\ncomplex coherence metrix, dtype cupy.complex\n\n\nds_ph\ntype\nndarray\ncomplex phase history, dtype cupy.complex\n\n\n\nThis function estimate the temporal coherence of DSs which is defined as [@ferrettiNewAlgorithmProcessing2011]:\n\\[\\gamma = \\frac{1}{N^2-N} \\sum_{n=1}^{N} \\sum_{k \\neq n}^{N} e^{i\\phi_{nk}} e^{-i(\\theta_n-\\theta_k)}\\]\nWhere \\(\\phi_{nk}\\) is the phase of complex coherence matrix and \\(\\theta_{n}\\) is the phase after phase linking.\n\n\nCode for generating data for test and doc\nrslc = zarr.open('../../data/rslc.zarr/','r')\nrslc = cp.asarray(rslc[:])\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndel rmli\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\nds_can_ph = emi(ds_can_coh)[0]\n\n\n\nds_can_coh.shape,ds_can_ph.shape\n\n((740397, 17, 17), (740397, 17))\n\n\n\nds_can_temp_coh = temp_coh(ds_can_coh,ds_can_ph)\nds_can_temp_coh.shape\n\n(740397,)\n\n\n\nds_can_temp_coh_2d = cp.empty_like(is_ds_can,dtype=ds_can_temp_coh.dtype)\nds_can_temp_coh_2d[:] = cp.nan\nds_can_temp_coh_2d[is_ds_can] = ds_can_temp_coh\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_temp_coh_2d),interpolation='nearest')\nax.set(title='DS Temporal Coherence',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "API/co.html",
    "href": "API/co.html",
    "title": "co",
    "section": "",
    "text": "For generating data for doc and test\nimport cupy as cp\nimport zarr\nfrom decorrelation.shp import ks_test\nimport math\nimport itertools\nfrom cupy.testing import assert_array_almost_equal"
  },
  {
    "objectID": "API/co.html#covariance-and-coherence-matrix-estimator",
    "href": "API/co.html#covariance-and-coherence-matrix-estimator",
    "title": "co",
    "section": "Covariance and Coherence Matrix Estimator",
    "text": "Covariance and Coherence Matrix Estimator\n\nsource\n\nemperical_co\n\n emperical_co (rslc:cupy.ndarray, is_shp:cupy.ndarray, block_size:int=128)\n\nMaximum likelihood covariance estimator.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nndarray\n\nrslc stack, dtype: cupy.complexfloating\n\n\nis_shp\nndarray\n\nshp bool, dtype: cupy.bool\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe covariance and coherence matrix cov and coh\n\n\n\nThe cov and coh is defined as:\n\\[\ncov = E(z_1z_2^*) \\quad coh=\\frac{E(z_1z_2^*)}{\\sqrt{E(|z_1|^2)E(|z_2|^2)}}\n\\]\nand estimated as:\n\\[\ncov = \\frac{\\sum_{i=1}^{L}z_1^{i}z_2^{i*}}{L} \\quad coh = \\frac{\\sum_{i=1}^{L}z_1^{i}z_2^{i*}}{\\sqrt(\\sum_{i=1}^{L}|z_1^{i}|^2)(\\sum_{i=1}^{L}|z_2^{i}|^2)}\n\\]\nusing all selected SHPs. Their shapes are [nlines,width,nimages,nimages].\nThe rslc is a three dimentional cupy ndarray. The dtype should be cupy.complex64. From outerest to innerest, the three dimentions are azimuth, range and image. is_shp is a four dimentional cupy ndarray. It describes if pixels in the search window are SHP to the central pixel. From outerest ot innerest, they are azimuth, range, secondary pixel relative azimuth, secondary pixel relative range.\nHere is an example:\n\n\nFor generating data for doc and test\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 3\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\n\n\nrslc.shape, is_shp.shape, is_shp[2,3]\n\n((5, 10, 17),\n (5, 10, 3, 5),\n array([[False, False, False, False,  True],\n        [False, False,  True, False, False],\n        [False, False,  True, False, False]]))\n\n\nrslc is a stack of 17 rslc images. Each of the image has 5 pixel in azimuth dimention and 10 pixels in range dimention. It shows for pixel (2,3), the (3*5) window around it has 2 SHPs to it (the central one is itself).\n\ncov,coh = emperical_co(rslc,is_shp)\ncov.shape, coh.shape\n\n((5, 10, 17, 17), (5, 10, 17, 17))\n\n\nBoth cov and coh are complex data. The shape shows each covarience or coherence matrix is 17 by 17 since there are 17 images. And cov and coh are matrix for all 5*10 pixels.\n\nsource\n\n\nemperical_co_sp\n\n emperical_co_sp (rslc:cupy.ndarray, sp_idx:cupy.ndarray,\n                  is_shp_sp:cupy.ndarray, block_size:int=128)\n\nMaximum likelihood covariance estimator for sparse data.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrslc\nndarray\n\nrslc stack, dtype: cupy.complexfloating\n\n\nsp_idx\nndarray\n\nindex of sparse data [azimuth_index, range_index], dtype: cupy.int, shape: (n_sp,2)\n\n\nis_shp_sp\nndarray\n\nshp bool, dtype: cupy.bool\n\n\nblock_size\nint\n128\nthe CUDA block size, it only affects the calculation speed\n\n\nReturns\ntuple\n\nthe covariance and coherence matrix cov and coh\n\n\n\nemperical_co_sp is the emperical_co on sparse data, e.g., DSs. rslc is same as emperical_co. sp_idx is the index, i.e., a tuple of (azimuth_idx, range_idx). Each index is 1D array. is_shp_sp is similar to is_shp in emperical_co but it only contains information about the sparse data. It is a 3D array with shape [number_of_point,az_win,r_win].\nCompared with emperical_co, emperical_co_sp only estimate coherence/covariance at specific position so the memory usage is much small.\nExample:\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 3\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\n\n\nrslc.shape,ds_can_idx,ds_can_is_shp\n\n((5, 10, 17),\n (array([2, 3, 3, 4, 4]), array([3, 3, 5, 1, 4])),\n array([[[False, False, False, False,  True],\n         [False, False,  True, False, False],\n         [False, False,  True, False, False]],\n \n        [[False, False,  True, False, False],\n         [False, False,  True, False, False],\n         [False, False, False,  True, False]],\n \n        [[False, False, False, False, False],\n         [False, False,  True, False, False],\n         [ True,  True, False, False, False]],\n \n        [[False, False,  True, False, False],\n         [False,  True,  True, False, False],\n         [False, False, False, False, False]],\n \n        [[False,  True,  True,  True, False],\n         [False, False,  True, False,  True],\n         [False, False, False, False, False]]]))\n\n\nrslc is a stack of 17 rslc images. Each of the image has 5 pixel in azimuth dimention and 10 pixels in range dimention. ds_can_idx shows the index of the DS candidates and ds_can_is_shp shows the corrosponding SHPs.\n\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)"
  },
  {
    "objectID": "API/co.html#covariance-and-coherence-matrix-regularizer",
    "href": "API/co.html#covariance-and-coherence-matrix-regularizer",
    "title": "co",
    "section": "Covariance and Coherence Matrix Regularizer",
    "text": "Covariance and Coherence Matrix Regularizer\n\nsource\n\nisPD\n\n isPD (co:cupy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nco\nndarray\nabsolute value of complex coherence/covariance stack\n\n\nReturns\nndarray\nbool array indicating wheather coherence/covariance is positive define\n\n\n\nThis function tells if the matrix is positive defined or not.\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:650,600:650]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 5; r_half_win = 5\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\n# Select DS candidate\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nis_ds_can = shp_num >= 50\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\n\nds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)[1]\n\n\n\nds_can_coh.shape\n\n(149, 17, 17)\n\n\n\nisPD_ds_can = isPD(ds_can_coh)\n\n\nisPD_ds_can\n\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True])\n\n\nAll coherence matrix are positive defined.\n\nsource\n\n\nnearestPD\n\n nearestPD (co:cupy.ndarray)\n\nFind the nearest positive-definite matrix to input matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nco\nndarray\nstack of matrix with shape […,N,N]\n\n\nReturns\nndarray\nnearest positive definite matrix of input, shape […,N,N]\n\n\n\nnearest means the Frobenius norm of the difference is minimized.\n\nsource\n\n\nregularize_spectral\n\n regularize_spectral (coh:cupy.ndarray, beta:Union[float,cupy.ndarray])\n\nSpectral regularizer for coherence matrix.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncoh\nndarray\nstack of matrix with shape […,N,N]\n\n\nbeta\nUnion\nthe regularization parameter, a float number or cupy ndarray with shape […]\n\n\nReturns\nndarray\nregularized matrix, shape […,N,N]\n\n\n\nregularize_spectral can regularize the absolute value of coherence matrix for better phase linking. It is first presented in [@zwiebackCheapValidRegularizers2022a].\nExamples:\n\n\nCode for generating data for doc\nrslc = zarr.open('../../data/rslc.zarr/','r')[600:605,600:610]\nrslc = cp.asarray(rslc)\n\n# SHP selection\naz_half_win = 1; r_half_win = 2\naz_win = 2*az_half_win+1; r_win = 2*r_half_win+1\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\ndist,p = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)\nis_shp = (p < 0.05) & (p >= 0.0)\n\ncov,coh = emperical_co(rslc,is_shp)\n\n\n\ncoh.shape\n\n(5, 10, 17, 17)\n\n\n\nregularized_coh1 = regularize_spectral(coh,0.1)\n\nMore general, bata can be a cp.ndarray:\n\nbeta = cp.ones(coh.shape[:-2])/10\nregularized_coh2 = regularize_spectral(coh,beta)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "decorrelation",
    "section": "",
    "text": "Documentation"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "decorrelation",
    "section": "Install",
    "text": "Install\nInstall CuPy first, then:\nWith conda:\nconda install -c conda-forge decorrelation\nWith pip:\npip install decorrelation\nIn development mode:\ngit clone git@github.com:kanglcn/decorrelation.git ./decorrelation\ncd ./decorrelation\npip install -e '.[dev]'"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "decorrelation",
    "section": "How to use",
    "text": "How to use\n\nimport decorrelation as dc\n\nPlease refer to the Documentation for detailed usage.\nWarning!!! This package is under intensive development. API is subjected to change without any noticement."
  },
  {
    "objectID": "index.html#contact-us",
    "href": "index.html#contact-us",
    "title": "decorrelation",
    "section": "Contact us",
    "text": "Contact us\n\nMost discussion happens on GitHub. Feel free to open an issue or comment on any open issue or pull request.\nuse github discussions to ask questions or leave comments."
  },
  {
    "objectID": "index.html#contribution",
    "href": "index.html#contribution",
    "title": "decorrelation",
    "section": "Contribution",
    "text": "Contribution\n\nPull requests are welcomed! Before making a pull request, please open an issue to talk about it.\nWe have notice many excellent open-source packages are rarely paid attention to due to lake of documentation. The package is developed with the nbdev, a notebook-driven development platform. Developers only needs to simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging automatically."
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html",
    "href": "Tutorials/Adaptive_Multilook.html",
    "title": "Adaptive Multilook",
    "section": "",
    "text": "In this tutorial, we demostrate how to use decorrelation package to identify spatially homogeneous pixels, extimate the coherence matrix and compare the original interferogram, multilook intergerogram and the adaptive multilook interferogram."
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html#load-rslc-stack",
    "href": "Tutorials/Adaptive_Multilook.html#load-rslc-stack",
    "title": "Adaptive Multilook",
    "section": "Load rslc stack",
    "text": "Load rslc stack\n\ncp.cuda.Device(1).use()\n\n<CUDA Device 1>\n\n\n\nrslc = cp.load('../../data/rslc.npy')\nrslc.shape\n\n(2500, 1834, 17)"
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html#apply-ks-test",
    "href": "Tutorials/Adaptive_Multilook.html#apply-ks-test",
    "title": "Adaptive Multilook",
    "section": "Apply ks test",
    "text": "Apply ks test\n\nrmli = cp.abs(rslc)**2\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\np = ks_test(rmli,az_half_win=az_half_win,r_half_win=r_half_win)[1]\n\nCPU times: user 45.7 ms, sys: 28.6 ms, total: 74.3 ms\nWall time: 74.8 ms\n\n\nks_test in decorrelation package is extremely fast!"
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html#select-shps",
    "href": "Tutorials/Adaptive_Multilook.html#select-shps",
    "title": "Adaptive Multilook",
    "section": "Select SHPs",
    "text": "Select SHPs\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\nshp_num_np = cp.asnumpy(shp_num)\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(shp_num_np)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html#estimate-coherence-matrix",
    "href": "Tutorials/Adaptive_Multilook.html#estimate-coherence-matrix",
    "title": "Adaptive Multilook",
    "section": "Estimate coherence matrix",
    "text": "Estimate coherence matrix\n\ncoh = emperical_co(rslc,is_shp)[1]\n\nCPU times: user 226 ms, sys: 18.8 ms, total: 245 ms\nWall time: 253 ms"
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html#compare",
    "href": "Tutorials/Adaptive_Multilook.html#compare",
    "title": "Adaptive Multilook",
    "section": "Compare",
    "text": "Compare\nHere we compare 1-look interferogram, multilook interferogram and adaptive multilook interferogram\n\nref_image = 15\nsec_image = 16\n\n1 look interferogram:\n\ndiff = rslc[:,:,ref_image]*rslc[:,:,sec_image].conj()\n\nMultilook interferogram:\n\nml_diff = median_filter(diff,size=(az_win,r_win))\n\nAdaptive multilook interferogram:\n\nad_ml_diff = coh[:,:,ref_image,sec_image]\n\nThe plot background:\n\nplot_bg = rmli[:,:,0]\nplot_bg = cp.asnumpy(plot_bg)\nalpha = bg_alpha(plot_bg)\n\nPlot:\n\nfig,axes = plt.subplots(1,3,figsize=(24/2,7/2))\nxlabel = 'Range Index'\nylabel = 'Azimuth Index'\npcm0 = axes[0].imshow(cp.asnumpy(cp.angle(diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm1 = axes[1].imshow(cp.asnumpy(cp.angle(ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\npcm2 = axes[2].imshow(cp.asnumpy(cp.angle(ad_ml_diff)),alpha=alpha,interpolation='nearest',cmap='hsv')\nfor ax in axes:\n    ax.set(facecolor = \"black\")\naxes[0].set(title='Orignal Interferogram',xlabel=xlabel,ylabel=ylabel)\naxes[1].set(title=f'Multilook {az_win} by {r_win}',xlabel=xlabel,ylabel=ylabel)\naxes[2].set(title=f'Adaptively multilook {az_win} by {r_win}',xlabel=xlabel,ylabel=ylabel)\nfig.colorbar(pcm0,ax=axes[0])\nfig.colorbar(pcm1,ax=axes[1])\nfig.colorbar(pcm1,ax=axes[2])\nfig.show()"
  },
  {
    "objectID": "Tutorials/Adaptive_Multilook.html#conclusion",
    "href": "Tutorials/Adaptive_Multilook.html#conclusion",
    "title": "Adaptive Multilook",
    "section": "Conclusion",
    "text": "Conclusion\n\nAdaptive multilooking based on SHPs selection performs better than non-adaptive one;\nks_test and emperical_co implemented in decorrelation package are fast."
  },
  {
    "objectID": "Tutorials/DS_Processing.html",
    "href": "Tutorials/DS_Processing.html",
    "title": "DS Processing",
    "section": "",
    "text": "In this tutorial, we demostrate how to do standard DS processing with the decorrelation package."
  },
  {
    "objectID": "Tutorials/DS_Processing.html#load-rslc-stack",
    "href": "Tutorials/DS_Processing.html#load-rslc-stack",
    "title": "DS Processing",
    "section": "Load rslc stack",
    "text": "Load rslc stack\n\nrslc = cp.load('../../data/rslc.npy')\nrslc.shape\n\n(2500, 1834, 17)"
  },
  {
    "objectID": "Tutorials/DS_Processing.html#apply-ks-test",
    "href": "Tutorials/DS_Processing.html#apply-ks-test",
    "title": "DS Processing",
    "section": "Apply ks test",
    "text": "Apply ks test\n\nrmli = cp.abs(rslc)**2\nsorted_rmli = cp.sort(rmli,axis=-1)\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\n\np = ks_test(sorted_rmli,az_half_win=az_half_win,r_half_win=r_half_win)[1]"
  },
  {
    "objectID": "Tutorials/DS_Processing.html#select-shps",
    "href": "Tutorials/DS_Processing.html#select-shps",
    "title": "DS Processing",
    "section": "Select SHPs",
    "text": "Select SHPs\n\nis_shp = (p < 0.05) & (p >= 0.0)\n\n\nshp_num = cp.count_nonzero(is_shp,axis=(-2,-1))\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(shp_num),cmap=colorcet.cm.fire)\nax.set(title='Number of SHPs',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/DS_Processing.html#select-dss",
    "href": "Tutorials/DS_Processing.html#select-dss",
    "title": "DS Processing",
    "section": "Select DSs",
    "text": "Select DSs\nBefore doing further processing, delete some variables to save memory.\nHere we select DSs candidate as pixels have more than 50 brothers.\n\nis_ds_can = shp_num >= 50\n\nThe number of DSs:\n\ncp.count_nonzero(is_ds_can)\n\narray(740397)\n\n\nThe DSs distribution:\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(is_ds_can),cmap=colorcet.cm.fire)\nax.set(title='DS Candidate distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/DS_Processing.html#estimate-coherence-matrix",
    "href": "Tutorials/DS_Processing.html#estimate-coherence-matrix",
    "title": "DS Processing",
    "section": "Estimate coherence matrix",
    "text": "Estimate coherence matrix\nIn order to save memory, here we only estimate coherence matrix on selected DSs:\n\nds_can_is_shp = is_shp[is_ds_can]\nds_can_idx = cp.where(is_ds_can)\nds_can_cov, ds_can_coh = emperical_co_sp(rslc,ds_can_idx,ds_can_is_shp)\n\nPlot the average coherence matrix:\n\nds_can_ave_coh = abs(ds_can_coh).mean(axis=0)\n\n\nds_can_ave_coh.shape\n\n(17, 17)\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\npcm = ax.imshow(cp.asnumpy(ds_can_ave_coh),cmap=colorcet.cm.fire)\nax.set(title='Average Coherence Matrix',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\nThe coherence between the 5-th SLC and other SLC are bad. We may consider removing this image."
  },
  {
    "objectID": "Tutorials/DS_Processing.html#phase-linking",
    "href": "Tutorials/DS_Processing.html#phase-linking",
    "title": "DS Processing",
    "section": "Phase linking",
    "text": "Phase linking\nHere we apply the EMI method:\n\nds_can_ph, ds_can_emi_quality = emi(ds_can_coh)\nds_can_ph.shape, ds_can_emi_quality.shape\n\n((740397, 17), (740397,))\n\n\n\nds_can_emi_quality_2d = cp.empty_like(is_ds_can,dtype=ds_can_emi_quality.dtype)\nds_can_emi_quality_2d[:] = cp.nan\nds_can_emi_quality_2d[is_ds_can] = ds_can_emi_quality\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_emi_quality_2d),interpolation='nearest',vmin=1,vmax=1.3)\nax.set(title='DS EMI quality factor',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nds_can_temp_coh = temp_coh(ds_can_coh,ds_can_ph)\nds_can_temp_coh.shape\n\n(740397,)\n\n\n\nds_can_temp_coh_2d = cp.empty_like(is_ds_can,dtype=ds_can_temp_coh.dtype)\nds_can_temp_coh_2d[:] = cp.nan\nds_can_temp_coh_2d[is_ds_can] = ds_can_temp_coh\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(ds_can_temp_coh_2d),interpolation='nearest')\nax.set(title='DS Temporal Coherence',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()"
  },
  {
    "objectID": "Tutorials/DS_Processing.html#refine-ds-candidate",
    "href": "Tutorials/DS_Processing.html#refine-ds-candidate",
    "title": "DS Processing",
    "section": "Refine DS candidate",
    "text": "Refine DS candidate\nHere we select DS candidate based on EMI quality factor and temporal coherence:\n\n_is_ds_can_refined = (ds_can_emi_quality>=1.0) & (ds_can_emi_quality <1.2) & (ds_can_temp_coh > 0.7) & (ds_can_temp_coh <= 1.0)\n\n\nds_can_refined_idx = tuple(idx[_is_ds_can_refined] for idx in ds_can_idx)\nis_ds_can_refined = cp.zeros_like(is_ds_can)\nis_ds_can_refined[ds_can_refined_idx] = True\n\n\nds_can_refined_coh = ds_can_coh[_is_ds_can_refined]\nds_can_refined_ph = ds_can_ph[_is_ds_can_refined]\n\n\nds_can_refined_coh.shape\n\n(460076, 17, 17)\n\n\nPlot the average coherence matrix and refined DS candiate distribution:\n\nds_can_refined_ave_coh = abs(ds_can_refined_coh).mean(axis=0)\nfig, ax = plt.subplots(1,1,figsize=(15,10))\npcm = ax.imshow(cp.asnumpy(ds_can_refined_ave_coh),cmap=colorcet.cm.fire)\nax.set(title='Average Coherence Matrix',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\n\nfig, ax = plt.subplots(1,1,figsize=(10,10))\npcm = ax.imshow(cp.asnumpy(is_ds_can_refined),cmap=colorcet.cm.fire)\nax.set(title='DS Candidate Refined distribution',xlabel='Range Index',ylabel='Azimuth Index')\nfig.colorbar(pcm)\nfig.show()\n\n\n\n\nWe find the coherence matrix gets better and noisy pixels are moved."
  },
  {
    "objectID": "Tutorials/Work_With_Dask.html",
    "href": "Tutorials/Work_With_Dask.html",
    "title": "Test",
    "section": "",
    "text": "import numpy as np\nimport zarr\nimport cupy as cp\nfrom itertools import product\n\nfrom decorrelation.shp import ks_test\nfrom decorrelation.co import emperical_co_sp\nfrom decorrelation.pl import emi\nIn this tutorial, we demostrate how to use Dask for distributed computing.\nTwo significant issues for InSAR big data processing are: 1) the memory of CPU/GPU does not fit the volume of very big data; 2) the processing speed is limited. For the first issue, one common solution is divide the data into independent chunks and process the chunks one by one. In many case, the processing of chunks are independent. Thus the processing can be speeded up by parallel processing.\nDask is a job scheduler that allows deploying process-level parallel processing. Through the Delayed feature, Dask operations only construct the computing workflow rather than do the computation immediately. All of the computations are done at the end to allow Dask better distributing computing resources for the task. Dask makes the parallel processing easier and enable the decoupling of codes for computation and codes for scheduling.\nIn this demo, we use Dask for multi-GPU KS test. This includes:"
  },
  {
    "objectID": "Tutorials/Work_With_Dask.html#processing",
    "href": "Tutorials/Work_With_Dask.html#processing",
    "title": "Test",
    "section": "Processing",
    "text": "Processing\nLoad data into CPU, the chunk size is setted:\n\nrslc_path = '../../data/rslc.zarr'\nrslc_zarr = zarr.open(rslc_path,mode='r')\ncpu_rslc = da.from_zarr(rslc_path,chunks=(1000,1000,17))\n\nThen convert to GPU:\n\nrslc = cpu_rslc.map_blocks(cp.asarray)\n\n\nrslc\n\n\n\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         594.67 MiB \n                         129.70 MiB \n                    \n                    \n                    \n                         Shape \n                         (2500, 1834, 17) \n                         (1000, 1000, 17) \n                    \n                    \n                         Dask graph \n                         6 chunks in 3 graph layers \n                    \n                    \n                         Data type \n                         complex64 cupy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  17\n  1834\n  2500\n\n        \n    \n\n\n\nPrepare the rmli and processing parameters:\n\nrmli = da.abs(rslc)**2\nrmli\n\n\n\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         297.34 MiB \n                         64.85 MiB \n                    \n                    \n                    \n                         Shape \n                         (2500, 1834, 17) \n                         (1000, 1000, 17) \n                    \n                    \n                         Dask graph \n                         6 chunks in 5 graph layers \n                    \n                    \n                         Data type \n                         float32 cupy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  17\n  1834\n  2500\n\n        \n    \n\n\n\n\naz_half_win = 5\nr_half_win = 5\naz_win = 2*az_half_win+1\nr_win = 2*r_half_win+1\n\nEnable overlapping between chunks. This is because the KS test is conducted on small region (az_win*r_win).\n\ndepth = {0:az_half_win, 1:r_half_win, 2:0}; boundary = {0:'none',1:'none',2:'none'}\nrmli_overlap = da.overlap.overlap(rmli,depth=depth, boundary=boundary)\nrmli_overlap\n\n\n\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         301.35 MiB \n                         65.83 MiB \n                    \n                    \n                    \n                         Shape \n                         (2520, 1844, 17) \n                         (1010, 1005, 17) \n                    \n                    \n                         Dask graph \n                         6 chunks in 6 graph layers \n                    \n                    \n                         Data type \n                         float32 cupy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  17\n  1844\n  2520\n\n        \n    \n\n\n\n\n# the array of delayed object will lost some shape information so perserve them here\nchunks_size = rmli_overlap.chunks \nnchunks = tuple(len(nchunks_in_each_dim) for nchunks_in_each_dim in chunks_size)\nchunks_shape = list(product(*chunks_size))\n\n\nchunks_size\n\n((1005, 1010, 505), (1005, 839), (17,))\n\n\n\nnchunks\n\n(3, 2, 1)\n\n\n\nchunks_shape\n\n[(1005, 1005, 17),\n (1005, 839, 17),\n (1010, 1005, 17),\n (1010, 839, 17),\n (505, 1005, 17),\n (505, 839, 17)]\n\n\nConvert each chunk to delayed object;\n\nrmli_chunks = rmli_overlap.to_delayed()\nrmli_chunks\n\narray([[[Delayed(('overlap-deeb6bf02a78ef34f82e8a8fcbd6af40', 0, 0, 0))],\n        [Delayed(('overlap-deeb6bf02a78ef34f82e8a8fcbd6af40', 0, 1, 0))]],\n\n       [[Delayed(('overlap-deeb6bf02a78ef34f82e8a8fcbd6af40', 1, 0, 0))],\n        [Delayed(('overlap-deeb6bf02a78ef34f82e8a8fcbd6af40', 1, 1, 0))]],\n\n       [[Delayed(('overlap-deeb6bf02a78ef34f82e8a8fcbd6af40', 2, 0, 0))],\n        [Delayed(('overlap-deeb6bf02a78ef34f82e8a8fcbd6af40', 2, 1, 0))]]],\n      dtype=object)\n\n\nApply the KS test:\n\ndelayed_ks_test = delayed(ks_test,pure=True,nout=2)\nresults = [delayed_ks_test(rmli_chunk,az_half_win=az_half_win,r_half_win=r_half_win) for rmli_chunk in rmli_chunks.ravel()]\ndist_chunks, p_chunks = zip(*results)\ndist_chunks, p_chunks = np.array(dist_chunks), np.array(p_chunks)\n\n\ndist_chunks\n\narray([Delayed('getitem-f50335529b047b79b2c90cdef57d40fd'),\n       Delayed('getitem-4ce12862641d4b5c6c4cc84e652dabc2'),\n       Delayed('getitem-c0334ded367e1297dcd1fed323c211e8'),\n       Delayed('getitem-da7af3e1e8721cc553402893fa56e087'),\n       Delayed('getitem-237696b05fba3e9aec0a3bc835be6a4b'),\n       Delayed('getitem-cac2e878f9a43c9f1da9233851482b57')], dtype=object)\n\n\nConvert Delayed object to dask array:\n\nfor i in range(len(chunks_shape)):\n    dist_chunks[i] = da.from_delayed(dist_chunks[i],shape=(*chunks_shape[i][:-1],az_win,r_win),meta=cp.array((),dtype=rmli.dtype))\n    p_chunks[i] = da.from_delayed(p_chunks[i],shape=(*chunks_shape[i][:-1],az_win,r_win),meta=cp.array((),dtype=rmli.dtype))\n\n\ndist_chunks\n\narray([dask.array<from-value, shape=(1005, 1005, 11, 11), dtype=float32, chunksize=(1005, 1005, 11, 11), chunktype=cupy.ndarray>,\n       dask.array<from-value, shape=(1005, 839, 11, 11), dtype=float32, chunksize=(1005, 839, 11, 11), chunktype=cupy.ndarray>,\n       dask.array<from-value, shape=(1010, 1005, 11, 11), dtype=float32, chunksize=(1010, 1005, 11, 11), chunktype=cupy.ndarray>,\n       dask.array<from-value, shape=(1010, 839, 11, 11), dtype=float32, chunksize=(1010, 839, 11, 11), chunktype=cupy.ndarray>,\n       dask.array<from-value, shape=(505, 1005, 11, 11), dtype=float32, chunksize=(505, 1005, 11, 11), chunktype=cupy.ndarray>,\n       dask.array<from-value, shape=(505, 839, 11, 11), dtype=float32, chunksize=(505, 839, 11, 11), chunktype=cupy.ndarray>],\n      dtype=object)\n\n\nReshape and concentate the dask array:\n\ndist_chunks, p_chunks = dist_chunks.reshape((*nchunks,1)).tolist(), p_chunks.reshape((*nchunks,1)).tolist()\n\n\ndist_chunks\n\n[[[[dask.array<from-value, shape=(1005, 1005, 11, 11), dtype=float32, chunksize=(1005, 1005, 11, 11), chunktype=cupy.ndarray>]],\n  [[dask.array<from-value, shape=(1005, 839, 11, 11), dtype=float32, chunksize=(1005, 839, 11, 11), chunktype=cupy.ndarray>]]],\n [[[dask.array<from-value, shape=(1010, 1005, 11, 11), dtype=float32, chunksize=(1010, 1005, 11, 11), chunktype=cupy.ndarray>]],\n  [[dask.array<from-value, shape=(1010, 839, 11, 11), dtype=float32, chunksize=(1010, 839, 11, 11), chunktype=cupy.ndarray>]]],\n [[[dask.array<from-value, shape=(505, 1005, 11, 11), dtype=float32, chunksize=(505, 1005, 11, 11), chunktype=cupy.ndarray>]],\n  [[dask.array<from-value, shape=(505, 839, 11, 11), dtype=float32, chunksize=(505, 839, 11, 11), chunktype=cupy.ndarray>]]]]\n\n\n\ndist = da.block(dist_chunks)\np = da.block(p_chunks)\n\n\ndist\n\n\n\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         2.09 GiB \n                         468.53 MiB \n                    \n                    \n                    \n                         Shape \n                         (2520, 1844, 11, 11) \n                         (1010, 1005, 11, 11) \n                    \n                    \n                         Dask graph \n                         6 chunks in 23 graph layers \n                    \n                    \n                         Data type \n                         float32 cupy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  2520\n  1\n\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  11\n  11\n  1844\n\n        \n    \n\n\n\n\np\n\n\n\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         2.09 GiB \n                         468.53 MiB \n                    \n                    \n                    \n                         Shape \n                         (2520, 1844, 11, 11) \n                         (1010, 1005, 11, 11) \n                    \n                    \n                         Dask graph \n                         6 chunks in 23 graph layers \n                    \n                    \n                         Data type \n                         float32 cupy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  2520\n  1\n\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  11\n  11\n  1844\n\n        \n    \n\n\n\n\ndist.chunks\n\n((1005, 1010, 505), (1005, 839), (11,), (11,))\n\n\nTrim the overlap region:\n\ndepth = {0:az_half_win, 1:r_half_win, 2:0, 3:0}; boundary = {0:'none',1:'none',2:'none',3:'none'}\ndist = da.overlap.trim_overlap(dist,depth=depth,boundary=boundary)\np = da.overlap.trim_overlap(p,depth=depth,boundary=boundary)\n\n\ndist.chunks\n\n((1000, 1000, 500), (1000, 834), (11,), (11,))\n\n\nCopy data from GPU to CPU:\n\ncpu_dist = da.map_blocks(cp.asnumpy,dist)\ncpu_p = da.map_blocks(cp.asnumpy,p)\n\n\ncpu_dist\n\n\n\n    \n        \n            \n                \n                    \n                         \n                         Array \n                         Chunk \n                    \n                \n                \n                    \n                    \n                         Bytes \n                         2.07 GiB \n                         461.58 MiB \n                    \n                    \n                    \n                         Shape \n                         (2500, 1834, 11, 11) \n                         (1000, 1000, 11, 11) \n                    \n                    \n                         Dask graph \n                         6 chunks in 26 graph layers \n                    \n                    \n                         Data type \n                         float32 numpy.ndarray \n                    \n                \n            \n        \n        \n        \n\n  \n  \n  \n\n  \n  \n  \n  \n  \n\n  \n  \n\n  \n  2500\n  1\n\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n  \n\n  \n  11\n  11\n  1834\n\n        \n    \n\n\n\nSave the data to disk:\n\ncpu_dist.to_zarr('dist.zarr',overwrite=True)\ncpu_p.to_zarr('p.zarr',overwrite=True)\n\nCPU times: user 909 ms, sys: 885 ms, total: 1.79 s\nWall time: 39.1 s\n\n\n\ndask_dist = zarr.load('dist.zarr')\ndask_p = zarr.load('p.zarr')\ndist = zarr.load('../../data/dist_ks.zarr/')\np = zarr.load('../../data/p_ks.zarr/')\n\n\nnp.testing.assert_array_equal(dask_dist,dist)\nnp.testing.assert_array_equal(dask_p,p)"
  }
]